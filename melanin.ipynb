{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI13JHHwHds4",
        "outputId": "88c78984-16b2-4753-8615-7ce89d6ce937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.6\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n",
            "Collecting optuna-integration[xgboost]\n",
            "  Downloading optuna_integration-4.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optuna-integration[xgboost]) (4.2.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from optuna-integration[xgboost]) (2.1.4)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optuna-integration[xgboost]) (6.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->optuna-integration[xgboost]) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost->optuna-integration[xgboost]) (1.14.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->optuna-integration[xgboost]) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[xgboost]) (3.1.1)\n",
            "Downloading optuna_integration-4.2.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: optuna-integration\n",
            "Successfully installed optuna-integration-4.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install optuna\n",
        "!pip install optuna-integration[xgboost]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Girxw7UK-mk4"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import time\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KNw43HZuIayz"
      },
      "outputs": [],
      "source": [
        "# upload this file to collab or clone this repo and add `data` directory with data\n",
        "melanin_df = pd.read_csv('./data/melanin.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8tALVMQjIpoR",
        "outputId": "75bf0a99-5a55-4346-cf8b-87795721eaff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCN(CC)CCNC(=O)c1ccc(cc1)N.Cl</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COCCNC(=O)CN1C2CCC1CC(C2)(c3cccnc3)O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC1=NN=C(c2cc3c(cc2C1)OCO3)c4ccc(cc4)N</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CC1C2Cc3ccc(cc3C1(CCN2CC=C)C)O</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COc1ccc(cc1)c2coc3cc(ccc3c2=O)OC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   SMILES  Class\n",
              "0           CCN(CC)CCNC(=O)c1ccc(cc1)N.Cl      1\n",
              "1    COCCNC(=O)CN1C2CCC1CC(C2)(c3cccnc3)O      1\n",
              "2  CC1=NN=C(c2cc3c(cc2C1)OCO3)c4ccc(cc4)N      1\n",
              "3          CC1C2Cc3ccc(cc3C1(CCN2CC=C)C)O      1\n",
              "4        COc1ccc(cc1)c2coc3cc(ccc3c2=O)OC      1"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "melanin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "5NH5Dx1sr0j8",
        "outputId": "0b5169c5-b6b8-443a-bcb3-f68aec1a87d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class\n",
              "1    607\n",
              "0    173\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "melanin_df.Class.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9JD_hoAIvyI",
        "outputId": "807501e5-8dea-443d-bb4e-778c41aada95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n",
            "/tmp/ipykernel_342134/2275780979.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)\n"
          ]
        }
      ],
      "source": [
        "descriptor_list = Descriptors.descList\n",
        "descriptors = []\n",
        "\n",
        "for descriptor in descriptor_list:\n",
        "      descriptors.append(descriptor[0])\n",
        "def get_descriptor_values(mol, descriptors):\n",
        "    calc = MolecularDescriptorCalculator(descriptors)\n",
        "    ds = calc.CalcDescriptors(mol)\n",
        "    return ds[0]\n",
        "for i in descriptors:\n",
        "    melanin_df[i] = pd.Series(np.array([get_descriptor_values(Chem.MolFromSmiles(j), [i]) for j in melanin_df[\"SMILES\"]]), index=melanin_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLG6bAktI7Un",
        "outputId": "6298258a-a3f3-48d6-cdbe-5238823ecdda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 780 entries, 0 to 779\n",
            "Columns: 212 entries, SMILES to fr_urea\n",
            "dtypes: float64(106), int64(105), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ],
      "source": [
        "melanin_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "8X4yxBgGKEyB",
        "outputId": "e4063b05-ef02-493e-af76-be29159bae65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NumRadicalElectrons</th>\n",
              "      <th>SMR_VSA8</th>\n",
              "      <th>SlogP_VSA9</th>\n",
              "      <th>fr_aldehyde</th>\n",
              "      <th>fr_azide</th>\n",
              "      <th>fr_azo</th>\n",
              "      <th>fr_barbitur</th>\n",
              "      <th>fr_diazo</th>\n",
              "      <th>fr_isocyan</th>\n",
              "      <th>fr_isothiocyan</th>\n",
              "      <th>fr_lactam</th>\n",
              "      <th>fr_nitroso</th>\n",
              "      <th>fr_phos_acid</th>\n",
              "      <th>fr_phos_ester</th>\n",
              "      <th>fr_prisulfonamd</th>\n",
              "      <th>fr_thiocyan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>776</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>777</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>780 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     NumRadicalElectrons  SMR_VSA8  SlogP_VSA9  fr_aldehyde  fr_azide  fr_azo  \\\n",
              "0                      0       0.0         0.0            0         0       0   \n",
              "1                      0       0.0         0.0            0         0       0   \n",
              "2                      0       0.0         0.0            0         0       0   \n",
              "3                      0       0.0         0.0            0         0       0   \n",
              "4                      0       0.0         0.0            0         0       0   \n",
              "..                   ...       ...         ...          ...       ...     ...   \n",
              "775                    0       0.0         0.0            0         0       0   \n",
              "776                    0       0.0         0.0            0         0       0   \n",
              "777                    0       0.0         0.0            0         0       0   \n",
              "778                    0       0.0         0.0            0         0       0   \n",
              "779                    0       0.0         0.0            0         0       0   \n",
              "\n",
              "     fr_barbitur  fr_diazo  fr_isocyan  fr_isothiocyan  fr_lactam  fr_nitroso  \\\n",
              "0              0         0           0               0          0           0   \n",
              "1              0         0           0               0          0           0   \n",
              "2              0         0           0               0          0           0   \n",
              "3              0         0           0               0          0           0   \n",
              "4              0         0           0               0          0           0   \n",
              "..           ...       ...         ...             ...        ...         ...   \n",
              "775            0         0           0               0          0           0   \n",
              "776            0         0           0               0          0           0   \n",
              "777            0         0           0               0          0           0   \n",
              "778            0         0           0               0          0           0   \n",
              "779            0         0           0               0          0           0   \n",
              "\n",
              "     fr_phos_acid  fr_phos_ester  fr_prisulfonamd  fr_thiocyan  \n",
              "0               0              0                0            0  \n",
              "1               0              0                0            0  \n",
              "2               0              0                0            0  \n",
              "3               0              0                0            0  \n",
              "4               0              0                0            0  \n",
              "..            ...            ...              ...          ...  \n",
              "775             0              0                0            0  \n",
              "776             0              0                0            0  \n",
              "777             0              0                0            0  \n",
              "778             0              0                0            0  \n",
              "779             0              0                0            0  \n",
              "\n",
              "[780 rows x 16 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "single_value_columns = melanin_df.columns[melanin_df.nunique() == 1]\n",
        "melanin_df[single_value_columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LBI3ulsNKWPY"
      },
      "outputs": [],
      "source": [
        "melanin_df.drop(columns=single_value_columns, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZRWlZgLRK36e"
      },
      "outputs": [],
      "source": [
        "corr_matrix = melanin_df.drop(columns=['SMILES', 'Class']).corr().abs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ufXtvv0gNJ8-",
        "outputId": "6289c1cc-3e28-43e1-b509-c860bae5ece3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MaxAbsEStateIndex</th>\n",
              "      <th>MaxEStateIndex</th>\n",
              "      <th>MinAbsEStateIndex</th>\n",
              "      <th>MinEStateIndex</th>\n",
              "      <th>qed</th>\n",
              "      <th>SPS</th>\n",
              "      <th>MolWt</th>\n",
              "      <th>HeavyAtomMolWt</th>\n",
              "      <th>ExactMolWt</th>\n",
              "      <th>NumValenceElectrons</th>\n",
              "      <th>...</th>\n",
              "      <th>fr_quatN</th>\n",
              "      <th>fr_sulfide</th>\n",
              "      <th>fr_sulfonamd</th>\n",
              "      <th>fr_sulfone</th>\n",
              "      <th>fr_term_acetylene</th>\n",
              "      <th>fr_tetrazole</th>\n",
              "      <th>fr_thiazole</th>\n",
              "      <th>fr_thiophene</th>\n",
              "      <th>fr_unbrch_alkane</th>\n",
              "      <th>fr_urea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MaxAbsEStateIndex</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.549487</td>\n",
              "      <td>0.517814</td>\n",
              "      <td>0.148163</td>\n",
              "      <td>0.145336</td>\n",
              "      <td>0.368054</td>\n",
              "      <td>0.374870</td>\n",
              "      <td>0.368826</td>\n",
              "      <td>0.385975</td>\n",
              "      <td>...</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.057079</td>\n",
              "      <td>0.132178</td>\n",
              "      <td>0.073312</td>\n",
              "      <td>0.036169</td>\n",
              "      <td>0.012941</td>\n",
              "      <td>0.022827</td>\n",
              "      <td>0.033263</td>\n",
              "      <td>0.014641</td>\n",
              "      <td>0.094043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MaxEStateIndex</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.549487</td>\n",
              "      <td>0.517814</td>\n",
              "      <td>0.148163</td>\n",
              "      <td>0.145336</td>\n",
              "      <td>0.368054</td>\n",
              "      <td>0.374870</td>\n",
              "      <td>0.368826</td>\n",
              "      <td>0.385975</td>\n",
              "      <td>...</td>\n",
              "      <td>0.068537</td>\n",
              "      <td>0.057079</td>\n",
              "      <td>0.132178</td>\n",
              "      <td>0.073312</td>\n",
              "      <td>0.036169</td>\n",
              "      <td>0.012941</td>\n",
              "      <td>0.022827</td>\n",
              "      <td>0.033263</td>\n",
              "      <td>0.014641</td>\n",
              "      <td>0.094043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MinAbsEStateIndex</th>\n",
              "      <td>0.549487</td>\n",
              "      <td>0.549487</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.364339</td>\n",
              "      <td>0.034567</td>\n",
              "      <td>0.103524</td>\n",
              "      <td>0.278091</td>\n",
              "      <td>0.278769</td>\n",
              "      <td>0.277457</td>\n",
              "      <td>0.265366</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067192</td>\n",
              "      <td>0.063719</td>\n",
              "      <td>0.070668</td>\n",
              "      <td>0.033836</td>\n",
              "      <td>0.033334</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>0.079464</td>\n",
              "      <td>0.116182</td>\n",
              "      <td>0.017031</td>\n",
              "      <td>0.024510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MinEStateIndex</th>\n",
              "      <td>0.517814</td>\n",
              "      <td>0.517814</td>\n",
              "      <td>0.364339</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.167352</td>\n",
              "      <td>0.111044</td>\n",
              "      <td>0.405698</td>\n",
              "      <td>0.419271</td>\n",
              "      <td>0.406025</td>\n",
              "      <td>0.381325</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017349</td>\n",
              "      <td>0.066786</td>\n",
              "      <td>0.493778</td>\n",
              "      <td>0.256334</td>\n",
              "      <td>0.013940</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.035509</td>\n",
              "      <td>0.025377</td>\n",
              "      <td>0.008451</td>\n",
              "      <td>0.031224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qed</th>\n",
              "      <td>0.148163</td>\n",
              "      <td>0.148163</td>\n",
              "      <td>0.034567</td>\n",
              "      <td>0.167352</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.176124</td>\n",
              "      <td>0.490615</td>\n",
              "      <td>0.495097</td>\n",
              "      <td>0.491267</td>\n",
              "      <td>0.487543</td>\n",
              "      <td>...</td>\n",
              "      <td>0.146499</td>\n",
              "      <td>0.055386</td>\n",
              "      <td>0.008351</td>\n",
              "      <td>0.019270</td>\n",
              "      <td>0.024371</td>\n",
              "      <td>0.024964</td>\n",
              "      <td>0.036488</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>0.329915</td>\n",
              "      <td>0.024415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr_tetrazole</th>\n",
              "      <td>0.012941</td>\n",
              "      <td>0.012941</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.024964</td>\n",
              "      <td>0.011923</td>\n",
              "      <td>0.022276</td>\n",
              "      <td>0.025766</td>\n",
              "      <td>0.022334</td>\n",
              "      <td>0.018236</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005913</td>\n",
              "      <td>0.013489</td>\n",
              "      <td>0.010123</td>\n",
              "      <td>0.005913</td>\n",
              "      <td>0.003150</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011071</td>\n",
              "      <td>0.075074</td>\n",
              "      <td>0.014392</td>\n",
              "      <td>0.009275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr_thiazole</th>\n",
              "      <td>0.022827</td>\n",
              "      <td>0.022827</td>\n",
              "      <td>0.079464</td>\n",
              "      <td>0.035509</td>\n",
              "      <td>0.036488</td>\n",
              "      <td>0.073606</td>\n",
              "      <td>0.023909</td>\n",
              "      <td>0.010955</td>\n",
              "      <td>0.023820</td>\n",
              "      <td>0.064786</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016955</td>\n",
              "      <td>0.038678</td>\n",
              "      <td>0.099615</td>\n",
              "      <td>0.016955</td>\n",
              "      <td>0.009034</td>\n",
              "      <td>0.011071</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.054805</td>\n",
              "      <td>0.041269</td>\n",
              "      <td>0.026595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr_thiophene</th>\n",
              "      <td>0.033263</td>\n",
              "      <td>0.033263</td>\n",
              "      <td>0.116182</td>\n",
              "      <td>0.025377</td>\n",
              "      <td>0.010505</td>\n",
              "      <td>0.062258</td>\n",
              "      <td>0.035183</td>\n",
              "      <td>0.022801</td>\n",
              "      <td>0.035300</td>\n",
              "      <td>0.092893</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022151</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>0.090126</td>\n",
              "      <td>0.036617</td>\n",
              "      <td>0.011802</td>\n",
              "      <td>0.075074</td>\n",
              "      <td>0.054805</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.040476</td>\n",
              "      <td>0.041169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr_unbrch_alkane</th>\n",
              "      <td>0.014641</td>\n",
              "      <td>0.014641</td>\n",
              "      <td>0.017031</td>\n",
              "      <td>0.008451</td>\n",
              "      <td>0.329915</td>\n",
              "      <td>0.086923</td>\n",
              "      <td>0.076669</td>\n",
              "      <td>0.051938</td>\n",
              "      <td>0.076973</td>\n",
              "      <td>0.129244</td>\n",
              "      <td>...</td>\n",
              "      <td>0.274662</td>\n",
              "      <td>0.027972</td>\n",
              "      <td>0.019777</td>\n",
              "      <td>0.022041</td>\n",
              "      <td>0.011744</td>\n",
              "      <td>0.014392</td>\n",
              "      <td>0.041269</td>\n",
              "      <td>0.040476</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr_urea</th>\n",
              "      <td>0.094043</td>\n",
              "      <td>0.094043</td>\n",
              "      <td>0.024510</td>\n",
              "      <td>0.031224</td>\n",
              "      <td>0.024415</td>\n",
              "      <td>0.029135</td>\n",
              "      <td>0.007940</td>\n",
              "      <td>0.006382</td>\n",
              "      <td>0.008080</td>\n",
              "      <td>0.018164</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014204</td>\n",
              "      <td>0.007779</td>\n",
              "      <td>0.026398</td>\n",
              "      <td>0.014204</td>\n",
              "      <td>0.007568</td>\n",
              "      <td>0.009275</td>\n",
              "      <td>0.026595</td>\n",
              "      <td>0.041169</td>\n",
              "      <td>0.008012</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194 rows × 194 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  \\\n",
              "MaxAbsEStateIndex           1.000000        1.000000           0.549487   \n",
              "MaxEStateIndex              1.000000        1.000000           0.549487   \n",
              "MinAbsEStateIndex           0.549487        0.549487           1.000000   \n",
              "MinEStateIndex              0.517814        0.517814           0.364339   \n",
              "qed                         0.148163        0.148163           0.034567   \n",
              "...                              ...             ...                ...   \n",
              "fr_tetrazole                0.012941        0.012941           0.008988   \n",
              "fr_thiazole                 0.022827        0.022827           0.079464   \n",
              "fr_thiophene                0.033263        0.033263           0.116182   \n",
              "fr_unbrch_alkane            0.014641        0.014641           0.017031   \n",
              "fr_urea                     0.094043        0.094043           0.024510   \n",
              "\n",
              "                   MinEStateIndex       qed       SPS     MolWt  \\\n",
              "MaxAbsEStateIndex        0.517814  0.148163  0.145336  0.368054   \n",
              "MaxEStateIndex           0.517814  0.148163  0.145336  0.368054   \n",
              "MinAbsEStateIndex        0.364339  0.034567  0.103524  0.278091   \n",
              "MinEStateIndex           1.000000  0.167352  0.111044  0.405698   \n",
              "qed                      0.167352  1.000000  0.176124  0.490615   \n",
              "...                           ...       ...       ...       ...   \n",
              "fr_tetrazole             0.005433  0.024964  0.011923  0.022276   \n",
              "fr_thiazole              0.035509  0.036488  0.073606  0.023909   \n",
              "fr_thiophene             0.025377  0.010505  0.062258  0.035183   \n",
              "fr_unbrch_alkane         0.008451  0.329915  0.086923  0.076669   \n",
              "fr_urea                  0.031224  0.024415  0.029135  0.007940   \n",
              "\n",
              "                   HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  ...  \\\n",
              "MaxAbsEStateIndex        0.374870    0.368826             0.385975  ...   \n",
              "MaxEStateIndex           0.374870    0.368826             0.385975  ...   \n",
              "MinAbsEStateIndex        0.278769    0.277457             0.265366  ...   \n",
              "MinEStateIndex           0.419271    0.406025             0.381325  ...   \n",
              "qed                      0.495097    0.491267             0.487543  ...   \n",
              "...                           ...         ...                  ...  ...   \n",
              "fr_tetrazole             0.025766    0.022334             0.018236  ...   \n",
              "fr_thiazole              0.010955    0.023820             0.064786  ...   \n",
              "fr_thiophene             0.022801    0.035300             0.092893  ...   \n",
              "fr_unbrch_alkane         0.051938    0.076973             0.129244  ...   \n",
              "fr_urea                  0.006382    0.008080             0.018164  ...   \n",
              "\n",
              "                   fr_quatN  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
              "MaxAbsEStateIndex  0.068537    0.057079      0.132178    0.073312   \n",
              "MaxEStateIndex     0.068537    0.057079      0.132178    0.073312   \n",
              "MinAbsEStateIndex  0.067192    0.063719      0.070668    0.033836   \n",
              "MinEStateIndex     0.017349    0.066786      0.493778    0.256334   \n",
              "qed                0.146499    0.055386      0.008351    0.019270   \n",
              "...                     ...         ...           ...         ...   \n",
              "fr_tetrazole       0.005913    0.013489      0.010123    0.005913   \n",
              "fr_thiazole        0.016955    0.038678      0.099615    0.016955   \n",
              "fr_thiophene       0.022151    0.000195      0.090126    0.036617   \n",
              "fr_unbrch_alkane   0.274662    0.027972      0.019777    0.022041   \n",
              "fr_urea            0.014204    0.007779      0.026398    0.014204   \n",
              "\n",
              "                   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiophene  \\\n",
              "MaxAbsEStateIndex           0.036169      0.012941     0.022827      0.033263   \n",
              "MaxEStateIndex              0.036169      0.012941     0.022827      0.033263   \n",
              "MinAbsEStateIndex           0.033334      0.008988     0.079464      0.116182   \n",
              "MinEStateIndex              0.013940      0.005433     0.035509      0.025377   \n",
              "qed                         0.024371      0.024964     0.036488      0.010505   \n",
              "...                              ...           ...          ...           ...   \n",
              "fr_tetrazole                0.003150      1.000000     0.011071      0.075074   \n",
              "fr_thiazole                 0.009034      0.011071     1.000000      0.054805   \n",
              "fr_thiophene                0.011802      0.075074     0.054805      1.000000   \n",
              "fr_unbrch_alkane            0.011744      0.014392     0.041269      0.040476   \n",
              "fr_urea                     0.007568      0.009275     0.026595      0.041169   \n",
              "\n",
              "                   fr_unbrch_alkane   fr_urea  \n",
              "MaxAbsEStateIndex          0.014641  0.094043  \n",
              "MaxEStateIndex             0.014641  0.094043  \n",
              "MinAbsEStateIndex          0.017031  0.024510  \n",
              "MinEStateIndex             0.008451  0.031224  \n",
              "qed                        0.329915  0.024415  \n",
              "...                             ...       ...  \n",
              "fr_tetrazole               0.014392  0.009275  \n",
              "fr_thiazole                0.041269  0.026595  \n",
              "fr_thiophene               0.040476  0.041169  \n",
              "fr_unbrch_alkane           1.000000  0.008012  \n",
              "fr_urea                    0.008012  1.000000  \n",
              "\n",
              "[194 rows x 194 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iVcEvA8LOJZy"
      },
      "outputs": [],
      "source": [
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
        "\n",
        "melanin_df.drop(to_drop, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "KRnmCeW6MOym",
        "outputId": "6080d36e-00e9-43e0-9e23-149cbd20ec12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Class</th>\n",
              "      <th>MaxAbsEStateIndex</th>\n",
              "      <th>MinAbsEStateIndex</th>\n",
              "      <th>MinEStateIndex</th>\n",
              "      <th>qed</th>\n",
              "      <th>SPS</th>\n",
              "      <th>MolWt</th>\n",
              "      <th>MaxPartialCharge</th>\n",
              "      <th>MinPartialCharge</th>\n",
              "      <th>...</th>\n",
              "      <th>fr_quatN</th>\n",
              "      <th>fr_sulfide</th>\n",
              "      <th>fr_sulfonamd</th>\n",
              "      <th>fr_sulfone</th>\n",
              "      <th>fr_term_acetylene</th>\n",
              "      <th>fr_tetrazole</th>\n",
              "      <th>fr_thiazole</th>\n",
              "      <th>fr_thiophene</th>\n",
              "      <th>fr_unbrch_alkane</th>\n",
              "      <th>fr_urea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCN(CC)CCNC(=O)c1ccc(cc1)N.Cl</td>\n",
              "      <td>1</td>\n",
              "      <td>11.743677</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.044300</td>\n",
              "      <td>0.775469</td>\n",
              "      <td>9.944444</td>\n",
              "      <td>271.792</td>\n",
              "      <td>0.250826</td>\n",
              "      <td>-0.398728</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COCCNC(=O)CN1C2CCC1CC(C2)(c3cccnc3)O</td>\n",
              "      <td>1</td>\n",
              "      <td>12.055486</td>\n",
              "      <td>0.033118</td>\n",
              "      <td>-0.816349</td>\n",
              "      <td>0.753573</td>\n",
              "      <td>30.347826</td>\n",
              "      <td>319.405</td>\n",
              "      <td>0.233779</td>\n",
              "      <td>-0.384987</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC1=NN=C(c2cc3c(cc2C1)OCO3)c4ccc(cc4)N</td>\n",
              "      <td>1</td>\n",
              "      <td>5.773582</td>\n",
              "      <td>0.263537</td>\n",
              "      <td>0.263537</td>\n",
              "      <td>0.821909</td>\n",
              "      <td>15.681818</td>\n",
              "      <td>293.326</td>\n",
              "      <td>0.230801</td>\n",
              "      <td>-0.453584</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CC1C2Cc3ccc(cc3C1(CCN2CC=C)C)O</td>\n",
              "      <td>1</td>\n",
              "      <td>9.798686</td>\n",
              "      <td>0.203036</td>\n",
              "      <td>0.203036</td>\n",
              "      <td>0.822957</td>\n",
              "      <td>33.789474</td>\n",
              "      <td>257.377</td>\n",
              "      <td>0.115392</td>\n",
              "      <td>-0.507956</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>COc1ccc(cc1)c2coc3cc(ccc3c2=O)OC</td>\n",
              "      <td>1</td>\n",
              "      <td>12.550924</td>\n",
              "      <td>0.065676</td>\n",
              "      <td>-0.065676</td>\n",
              "      <td>0.737634</td>\n",
              "      <td>10.571429</td>\n",
              "      <td>282.295</td>\n",
              "      <td>0.199993</td>\n",
              "      <td>-0.496768</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 158 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   SMILES  Class  MaxAbsEStateIndex  \\\n",
              "0           CCN(CC)CCNC(=O)c1ccc(cc1)N.Cl      1          11.743677   \n",
              "1    COCCNC(=O)CN1C2CCC1CC(C2)(c3cccnc3)O      1          12.055486   \n",
              "2  CC1=NN=C(c2cc3c(cc2C1)OCO3)c4ccc(cc4)N      1           5.773582   \n",
              "3          CC1C2Cc3ccc(cc3C1(CCN2CC=C)C)O      1           9.798686   \n",
              "4        COc1ccc(cc1)c2coc3cc(ccc3c2=O)OC      1          12.550924   \n",
              "\n",
              "   MinAbsEStateIndex  MinEStateIndex       qed        SPS    MolWt  \\\n",
              "0           0.000000       -0.044300  0.775469   9.944444  271.792   \n",
              "1           0.033118       -0.816349  0.753573  30.347826  319.405   \n",
              "2           0.263537        0.263537  0.821909  15.681818  293.326   \n",
              "3           0.203036        0.203036  0.822957  33.789474  257.377   \n",
              "4           0.065676       -0.065676  0.737634  10.571429  282.295   \n",
              "\n",
              "   MaxPartialCharge  MinPartialCharge  ...  fr_quatN  fr_sulfide  \\\n",
              "0          0.250826         -0.398728  ...         0           0   \n",
              "1          0.233779         -0.384987  ...         0           0   \n",
              "2          0.230801         -0.453584  ...         0           0   \n",
              "3          0.115392         -0.507956  ...         0           0   \n",
              "4          0.199993         -0.496768  ...         0           0   \n",
              "\n",
              "   fr_sulfonamd  fr_sulfone  fr_term_acetylene  fr_tetrazole  fr_thiazole  \\\n",
              "0             0           0                  0             0            0   \n",
              "1             0           0                  0             0            0   \n",
              "2             0           0                  0             0            0   \n",
              "3             0           0                  0             0            0   \n",
              "4             0           0                  0             0            0   \n",
              "\n",
              "   fr_thiophene  fr_unbrch_alkane  fr_urea  \n",
              "0             0                 0        0  \n",
              "1             0                 1        0  \n",
              "2             0                 0        0  \n",
              "3             0                 0        0  \n",
              "4             0                 0        0  \n",
              "\n",
              "[5 rows x 158 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "melanin_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1UcZwuZAO-Ah"
      },
      "outputs": [],
      "source": [
        "X = melanin_df.drop(columns=['SMILES', 'Class'])\n",
        "y = melanin_df['Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DdXn4gprP9T4"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1488)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "laHXxOR18kmG"
      },
      "outputs": [],
      "source": [
        "metric = 'auc'\n",
        "base_params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': metric,\n",
        "    'enable_categorical': True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q38cPefUJYHy"
      },
      "outputs": [],
      "source": [
        "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-r4Lc8OP8zo8"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'tree_method': trial.suggest_categorical('tree_method', ['approx', 'hist']),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 10),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 5, 12),\n",
        "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.001, 0.5, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 10000, 10000),\n",
        "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 50),\n",
        "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', scale_pos_weight, scale_pos_weight)\n",
        "    }\n",
        "    params.update(base_params)\n",
        "\n",
        "    # Add pruning callback\n",
        "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, f'validation_1-{metric}')\n",
        "\n",
        "    # Initialize XGBClassifier\n",
        "    model = XGBClassifier(callbacks=[pruning_callback], **params)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Save the best iteration for reference\n",
        "    trial.set_user_attr('best_iteration', model.best_iteration)\n",
        "\n",
        "    # Return the validation score\n",
        "    return model.best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yux0QBp9Vra",
        "outputId": "cd69ae11-b788-4f36-9437-7a7a4ced0afe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-03-30 02:40:58,606] A new study created in memory with name: no-name-c5f53b98-93a6-4279-8b0f-9b581589331d\n",
            "[I 2025-03-30 02:41:05,163] Trial 0 finished with value: 0.873435655253837 and parameters: {'tree_method': 'approx', 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.8889393258968677, 'colsample_bytree': 0.8258044087891845, 'reg_lambda': 0.05023256449955142, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:13,201] Trial 1 finished with value: 0.8369539551357733 and parameters: {'tree_method': 'approx', 'max_depth': 7, 'min_child_weight': 12, 'subsample': 0.47368572541632725, 'colsample_bytree': 0.5275802773931773, 'reg_lambda': 0.14804210086916686, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:18,461] Trial 2 finished with value: 0.8380165289256198 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.5181793974389851, 'colsample_bytree': 0.8124963168672132, 'reg_lambda': 0.03022640267849706, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:19,049] Trial 3 finished with value: 0.8223140495867769 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 11, 'subsample': 0.3377584589537188, 'colsample_bytree': 0.5247020263820545, 'reg_lambda': 0.21214898827797607, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:19,410] Trial 4 finished with value: 0.8415584415584415 and parameters: {'tree_method': 'hist', 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.49409972793375656, 'colsample_bytree': 0.9255755020107468, 'reg_lambda': 0.003423027108651802, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:19,454] Trial 5 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:19,680] Trial 6 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:19,964] Trial 7 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:21,180] Trial 8 pruned. Trial was pruned at iteration 8.\n",
            "[I 2025-03-30 02:41:21,442] Trial 9 finished with value: 0.8618654073199528 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8686706038119739, 'colsample_bytree': 0.8063413133448459, 'reg_lambda': 0.07383863551776056, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:22,046] Trial 10 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:22,493] Trial 11 finished with value: 0.859504132231405 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.8963491374201111, 'colsample_bytree': 0.7015017610630803, 'reg_lambda': 0.011751104625752148, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:22,918] Trial 12 finished with value: 0.8429752066115702 and parameters: {'tree_method': 'hist', 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.7507846813260068, 'colsample_bytree': 0.9983073908127154, 'reg_lambda': 0.06264196304378934, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:23,018] Trial 13 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:27,920] Trial 14 finished with value: 0.8634002361275088 and parameters: {'tree_method': 'approx', 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.7522381717958961, 'colsample_bytree': 0.8163985304379652, 'reg_lambda': 0.013257286042907391, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:27,970] Trial 15 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:28,453] Trial 16 pruned. Trial was pruned at iteration 5.\n",
            "[I 2025-03-30 02:41:28,728] Trial 17 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:28,922] Trial 18 pruned. Trial was pruned at iteration 3.\n",
            "[I 2025-03-30 02:41:37,108] Trial 19 finished with value: 0.8559622195985832 and parameters: {'tree_method': 'approx', 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.7971046155191268, 'colsample_bytree': 0.9701431889416684, 'reg_lambda': 0.007815312370979348, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:37,413] Trial 20 pruned. Trial was pruned at iteration 3.\n",
            "[I 2025-03-30 02:41:37,501] Trial 21 pruned. Trial was pruned at iteration 3.\n",
            "[I 2025-03-30 02:41:37,769] Trial 22 finished with value: 0.8593860684769775 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8762476635837374, 'colsample_bytree': 0.7662743818615521, 'reg_lambda': 0.04454836446893417, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:37,838] Trial 23 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:37,923] Trial 24 pruned. Trial was pruned at iteration 2.\n",
            "[I 2025-03-30 02:41:38,306] Trial 25 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:38,720] Trial 26 finished with value: 0.8727272727272727 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8380616558717716, 'colsample_bytree': 0.7553783705063959, 'reg_lambda': 0.015753449847750678, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:39,042] Trial 27 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:39,125] Trial 28 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:39,281] Trial 29 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:39,577] Trial 30 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:39,891] Trial 31 finished with value: 0.8550177095631641 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8474377281813485, 'colsample_bytree': 0.7917320235456728, 'reg_lambda': 0.045276806607074435, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:40,053] Trial 32 finished with value: 0.8700118063754427 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.9471575478907113, 'colsample_bytree': 0.8774067090650797, 'reg_lambda': 0.09758506840580725, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:40,125] Trial 33 pruned. Trial was pruned at iteration 3.\n",
            "[I 2025-03-30 02:41:40,460] Trial 34 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:40,522] Trial 35 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:40,598] Trial 36 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:41,133] Trial 37 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:41,223] Trial 38 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:41,351] Trial 39 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:41,443] Trial 40 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:41,674] Trial 41 finished with value: 0.8598583234946872 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8663490329607124, 'colsample_bytree': 0.8119968776990818, 'reg_lambda': 0.0705861460047435, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:41,742] Trial 42 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:42,438] Trial 43 finished with value: 0.8661157024793389 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9498994684990499, 'colsample_bytree': 0.8684630914249121, 'reg_lambda': 0.0498305039053241, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 0 with value: 0.873435655253837.\n",
            "[I 2025-03-30 02:41:42,637] Trial 44 pruned. Trial was pruned at iteration 3.\n",
            "[I 2025-03-30 02:41:42,768] Trial 45 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:42,910] Trial 46 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:50,901] Trial 47 finished with value: 0.8739079102715467 and parameters: {'tree_method': 'approx', 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8291677371824511, 'colsample_bytree': 0.9242764824955713, 'reg_lambda': 0.003772051727237365, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 47 with value: 0.8739079102715467.\n",
            "[I 2025-03-30 02:41:51,004] Trial 48 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:51,077] Trial 49 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:51,156] Trial 50 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:51,206] Trial 51 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:51,478] Trial 52 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:51,900] Trial 53 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:51,942] Trial 54 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:51,988] Trial 55 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:52,289] Trial 56 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:52,449] Trial 57 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:52,766] Trial 58 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:52,847] Trial 59 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:52,948] Trial 60 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:53,363] Trial 61 finished with value: 0.8596221959858323 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.862406893930889, 'colsample_bytree': 0.7693336156665225, 'reg_lambda': 0.1419008253217948, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 47 with value: 0.8739079102715467.\n",
            "[I 2025-03-30 02:41:53,438] Trial 62 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:53,592] Trial 63 pruned. Trial was pruned at iteration 3.\n",
            "[I 2025-03-30 02:41:53,698] Trial 64 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:53,999] Trial 65 finished with value: 0.8590318772136954 and parameters: {'tree_method': 'hist', 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.8797969767988786, 'colsample_bytree': 0.8925363421228527, 'reg_lambda': 0.10982379161466543, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 47 with value: 0.8739079102715467.\n",
            "[I 2025-03-30 02:41:54,189] Trial 66 finished with value: 0.8585596221959858 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8906496684573786, 'colsample_bytree': 0.944184329779837, 'reg_lambda': 0.04050516691724688, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 47 with value: 0.8739079102715467.\n",
            "[I 2025-03-30 02:41:54,556] Trial 67 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:54,641] Trial 68 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:54,731] Trial 69 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:54,847] Trial 70 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:55,246] Trial 71 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:55,357] Trial 72 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:55,532] Trial 73 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:55,635] Trial 74 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:56,069] Trial 75 finished with value: 0.868595041322314 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.9043724679019142, 'colsample_bytree': 0.8554874627613464, 'reg_lambda': 0.09056823639540813, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 47 with value: 0.8739079102715467.\n",
            "[I 2025-03-30 02:41:56,172] Trial 76 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:56,663] Trial 77 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:56,800] Trial 78 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:56,899] Trial 79 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:57,039] Trial 80 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:57,320] Trial 81 finished with value: 0.8668240850059031 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.869124288066541, 'colsample_bytree': 0.8070659950158844, 'reg_lambda': 0.04953500783732631, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 47 with value: 0.8739079102715467.\n",
            "[I 2025-03-30 02:41:57,465] Trial 82 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:57,555] Trial 83 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:57,938] Trial 84 pruned. Trial was pruned at iteration 2.\n",
            "[I 2025-03-30 02:41:58,029] Trial 85 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:58,110] Trial 86 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:58,436] Trial 87 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:58,636] Trial 88 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:59,341] Trial 89 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:41:59,442] Trial 90 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:41:59,548] Trial 91 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:00,317] Trial 92 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:00,469] Trial 93 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:01,121] Trial 94 finished with value: 0.8668240850059031 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.9490674688350801, 'colsample_bytree': 0.8838904578195622, 'reg_lambda': 0.07936623449725051, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 47 with value: 0.8739079102715467.\n",
            "[I 2025-03-30 02:42:01,448] Trial 95 finished with value: 0.864344746162928 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.9519096339406137, 'colsample_bytree': 0.9630601510562138, 'reg_lambda': 0.08456124850834729, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 47 with value: 0.8739079102715467.\n",
            "[I 2025-03-30 02:42:01,524] Trial 96 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:01,948] Trial 97 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:02,024] Trial 98 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:02,194] Trial 99 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:02,655] Trial 100 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:02,840] Trial 101 pruned. Trial was pruned at iteration 2.\n",
            "[I 2025-03-30 02:42:03,275] Trial 102 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8916071284914967, 'colsample_bytree': 0.964650553743322, 'reg_lambda': 0.043813194386386464, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 102 with value: 0.877331759149941.\n",
            "[I 2025-03-30 02:42:03,922] Trial 103 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8894701707419828, 'colsample_bytree': 0.9656404826782532, 'reg_lambda': 0.035149694622277884, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:05,905] Trial 104 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8873934110586987, 'colsample_bytree': 0.9675775184698355, 'reg_lambda': 0.04606949400930118, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:06,058] Trial 105 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.885581764568594, 'colsample_bytree': 0.9731456989630944, 'reg_lambda': 0.03514412932015032, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:06,243] Trial 106 finished with value: 0.8645808736717827 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8791963295162978, 'colsample_bytree': 0.9628629562756732, 'reg_lambda': 0.033265314830910914, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:06,307] Trial 107 pruned. Trial was pruned at iteration 2.\n",
            "[I 2025-03-30 02:42:06,370] Trial 108 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:06,616] Trial 109 finished with value: 0.8570247933884297 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 7, 'subsample': 0.9016303343402441, 'colsample_bytree': 0.9199459332201433, 'reg_lambda': 0.036397289117589875, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:07,125] Trial 110 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8866549362195265, 'colsample_bytree': 0.9771938975506578, 'reg_lambda': 0.045913661688338395, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:07,424] Trial 111 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8829396097033478, 'colsample_bytree': 0.9988939243772161, 'reg_lambda': 0.043104236763210936, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:07,687] Trial 112 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.88622007233506, 'colsample_bytree': 0.9838288098802047, 'reg_lambda': 0.043528936551555195, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:07,937] Trial 113 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8873115131884177, 'colsample_bytree': 0.9985663250729281, 'reg_lambda': 0.025377348842457244, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:08,092] Trial 114 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8883985793222785, 'colsample_bytree': 0.9996125521835649, 'reg_lambda': 0.0204059957725003, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:08,363] Trial 115 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8855553133201927, 'colsample_bytree': 0.9749252292458652, 'reg_lambda': 0.023008369907455483, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:09,034] Trial 116 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.887969230698853, 'colsample_bytree': 0.9787433802734758, 'reg_lambda': 0.02214397088154, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:09,214] Trial 117 finished with value: 0.8768595041322315 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8843218460074259, 'colsample_bytree': 0.9997000231175064, 'reg_lambda': 0.02263862821195895, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 103 with value: 0.8775678866587957.\n",
            "[I 2025-03-30 02:42:09,499] Trial 118 finished with value: 0.880047225501771 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8832189875922608, 'colsample_bytree': 0.9975624205287873, 'reg_lambda': 0.023953657047454315, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:09,551] Trial 119 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:09,900] Trial 120 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:10,168] Trial 121 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8907795367423985, 'colsample_bytree': 0.9939472428733512, 'reg_lambda': 0.02497463546910598, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:10,337] Trial 122 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.887856593620377, 'colsample_bytree': 0.9960372298114564, 'reg_lambda': 0.024916380537979878, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:10,408] Trial 123 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:10,521] Trial 124 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:10,634] Trial 125 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:10,868] Trial 126 finished with value: 0.863754427390791 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8997327272088882, 'colsample_bytree': 0.9996383175673796, 'reg_lambda': 0.03251761321863684, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:10,926] Trial 127 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:11,457] Trial 128 finished with value: 0.8798110979929161 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8829187405503663, 'colsample_bytree': 0.9834445195785485, 'reg_lambda': 0.020231167930344927, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:11,520] Trial 129 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:11,617] Trial 130 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:11,820] Trial 131 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8915768691579034, 'colsample_bytree': 0.9992805180368444, 'reg_lambda': 0.04403641838478034, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:11,868] Trial 132 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:11,914] Trial 133 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:11,960] Trial 134 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:12,012] Trial 135 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:12,065] Trial 136 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:12,120] Trial 137 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:12,172] Trial 138 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:12,224] Trial 139 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:12,336] Trial 140 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:12,536] Trial 141 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8871538740463736, 'colsample_bytree': 0.983310999736482, 'reg_lambda': 0.03961131150753084, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:12,658] Trial 142 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:12,822] Trial 143 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:12,918] Trial 144 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:13,019] Trial 145 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:13,085] Trial 146 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:13,180] Trial 147 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:13,241] Trial 148 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:13,574] Trial 149 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:13,968] Trial 150 finished with value: 0.8768595041322315 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.883824580981313, 'colsample_bytree': 0.9628614308009055, 'reg_lambda': 0.030533408162789318, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:14,622] Trial 151 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8855291241500526, 'colsample_bytree': 0.9818511055221194, 'reg_lambda': 0.043972046931651874, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:14,791] Trial 152 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:15,004] Trial 153 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:15,604] Trial 154 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8911303407460281, 'colsample_bytree': 0.9699214045772383, 'reg_lambda': 0.02737143429825423, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:15,719] Trial 155 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:15,925] Trial 156 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:15,991] Trial 157 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,072] Trial 158 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,150] Trial 159 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,370] Trial 160 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,420] Trial 161 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:16,469] Trial 162 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,514] Trial 163 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,568] Trial 164 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,636] Trial 165 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,702] Trial 166 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,858] Trial 167 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:16,937] Trial 168 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:17,136] Trial 169 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8910983419593632, 'colsample_bytree': 0.9997730817874263, 'reg_lambda': 0.02829712903922681, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:17,185] Trial 170 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:17,344] Trial 171 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8881250361399846, 'colsample_bytree': 0.9719219192578242, 'reg_lambda': 0.030376234393680986, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:17,388] Trial 172 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:17,436] Trial 173 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:17,485] Trial 174 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:17,533] Trial 175 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:17,582] Trial 176 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:17,633] Trial 177 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:17,684] Trial 178 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:17,732] Trial 179 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:17,780] Trial 180 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:17,919] Trial 181 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8876998418251155, 'colsample_bytree': 0.9819119338497283, 'reg_lambda': 0.05289457675053278, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:17,969] Trial 182 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:18,135] Trial 183 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8880042732885854, 'colsample_bytree': 0.9355970405384069, 'reg_lambda': 0.03716581058642143, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:18,184] Trial 184 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:18,232] Trial 185 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:18,282] Trial 186 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:18,334] Trial 187 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:18,384] Trial 188 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:18,436] Trial 189 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:18,589] Trial 190 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8895015569933934, 'colsample_bytree': 0.9854359682432111, 'reg_lambda': 0.019566309938134414, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:18,883] Trial 191 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8895952400391585, 'colsample_bytree': 0.9835796077302339, 'reg_lambda': 0.021827684073287754, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:18,942] Trial 192 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:19,018] Trial 193 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:19,069] Trial 194 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:19,301] Trial 195 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:19,353] Trial 196 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:19,406] Trial 197 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:19,454] Trial 198 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:19,501] Trial 199 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:19,701] Trial 200 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:19,859] Trial 201 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8873550206224471, 'colsample_bytree': 0.9667392350222778, 'reg_lambda': 0.03626811397145476, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:20,048] Trial 202 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8885269814436388, 'colsample_bytree': 0.9770924105595897, 'reg_lambda': 0.04261815263945066, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:20,115] Trial 203 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:20,205] Trial 204 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:20,334] Trial 205 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:20,430] Trial 206 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:20,492] Trial 207 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:20,575] Trial 208 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:20,636] Trial 209 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:20,698] Trial 210 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:21,120] Trial 211 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8922744975666206, 'colsample_bytree': 0.9817342732701669, 'reg_lambda': 0.043737697833200646, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:21,503] Trial 212 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8920711588751266, 'colsample_bytree': 0.9833307311898715, 'reg_lambda': 0.04356977135727497, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:21,558] Trial 213 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:21,608] Trial 214 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:21,657] Trial 215 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:21,714] Trial 216 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:21,765] Trial 217 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:21,815] Trial 218 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:21,875] Trial 219 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:22,139] Trial 220 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:22,311] Trial 221 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:22,380] Trial 222 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:22,586] Trial 223 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:22,649] Trial 224 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:22,704] Trial 225 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:22,759] Trial 226 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:22,962] Trial 227 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8863590308155572, 'colsample_bytree': 0.9678457151295867, 'reg_lambda': 0.02756816235444589, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:23,012] Trial 228 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:23,059] Trial 229 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:23,106] Trial 230 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:23,266] Trial 231 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8905568500729857, 'colsample_bytree': 0.9832504218100848, 'reg_lambda': 0.04211333738398459, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:23,394] Trial 232 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8870037938015622, 'colsample_bytree': 0.9832214373626595, 'reg_lambda': 0.04914717323336338, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:23,440] Trial 233 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:23,486] Trial 234 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:23,534] Trial 235 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:23,581] Trial 236 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:23,629] Trial 237 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:23,728] Trial 238 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:23,828] Trial 239 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:23,927] Trial 240 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:24,100] Trial 241 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8883475527635608, 'colsample_bytree': 0.9997034711807399, 'reg_lambda': 0.042058639982738066, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:24,233] Trial 242 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8821791843869854, 'colsample_bytree': 0.9789346678842701, 'reg_lambda': 0.04363633611129824, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:24,313] Trial 243 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:24,395] Trial 244 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:24,491] Trial 245 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:24,580] Trial 246 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:24,719] Trial 247 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8849368581255252, 'colsample_bytree': 0.9852917720311468, 'reg_lambda': 0.024360536189037735, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:24,799] Trial 248 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:24,888] Trial 249 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:24,951] Trial 250 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:25,036] Trial 251 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:25,116] Trial 252 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:25,302] Trial 253 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:25,465] Trial 254 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:25,785] Trial 255 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8870336551058607, 'colsample_bytree': 0.9829265238956435, 'reg_lambda': 0.03539332462065624, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:25,872] Trial 256 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:25,963] Trial 257 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:26,058] Trial 258 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:26,495] Trial 259 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8857599235824368, 'colsample_bytree': 0.9725960336399203, 'reg_lambda': 0.019982731871922566, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:26,676] Trial 260 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:26,760] Trial 261 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:26,880] Trial 262 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:26,995] Trial 263 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:27,066] Trial 264 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:27,903] Trial 265 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8887301891679217, 'colsample_bytree': 0.9811976330036233, 'reg_lambda': 0.034040595390166566, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:27,970] Trial 266 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:28,086] Trial 267 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:28,164] Trial 268 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:28,606] Trial 269 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.885887593803063, 'colsample_bytree': 0.9999525433980719, 'reg_lambda': 0.03038078616875382, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:28,721] Trial 270 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:28,870] Trial 271 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:28,949] Trial 272 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:28,997] Trial 273 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:29,044] Trial 274 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:29,090] Trial 275 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:29,216] Trial 276 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.888198408356503, 'colsample_bytree': 0.979482707613258, 'reg_lambda': 0.029286018313506194, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:29,706] Trial 277 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:29,754] Trial 278 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:29,800] Trial 279 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:29,847] Trial 280 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:29,894] Trial 281 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:30,019] Trial 282 finished with value: 0.8775678866587957 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8890607577723009, 'colsample_bytree': 0.9591716390275953, 'reg_lambda': 0.03448949826013905, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:30,072] Trial 283 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:30,188] Trial 284 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:30,281] Trial 285 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:30,889] Trial 286 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8850693871369918, 'colsample_bytree': 0.9672155044979741, 'reg_lambda': 0.033081117822804366, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:31,034] Trial 287 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:31,119] Trial 288 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:31,287] Trial 289 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:31,411] Trial 290 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:31,639] Trial 291 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:31,703] Trial 292 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:32,150] Trial 293 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:32,255] Trial 294 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:32,471] Trial 295 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:32,574] Trial 296 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:32,987] Trial 297 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:33,066] Trial 298 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:33,626] Trial 299 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:33,783] Trial 300 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:33,925] Trial 301 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8845250770246538, 'colsample_bytree': 0.9525762246634533, 'reg_lambda': 0.029836551206852312, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:33,973] Trial 302 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:34,025] Trial 303 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:34,089] Trial 304 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:34,170] Trial 305 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:34,349] Trial 306 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8877881334990213, 'colsample_bytree': 0.9339439587149402, 'reg_lambda': 0.06652677923651248, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:34,403] Trial 307 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:34,542] Trial 308 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:34,640] Trial 309 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:34,976] Trial 310 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:35,208] Trial 311 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:35,358] Trial 312 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:35,424] Trial 313 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:35,480] Trial 314 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:35,539] Trial 315 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:35,808] Trial 316 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:35,889] Trial 317 pruned. Trial was pruned at iteration 2.\n",
            "[I 2025-03-30 02:42:35,952] Trial 318 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:36,007] Trial 319 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:36,069] Trial 320 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:36,350] Trial 321 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:36,433] Trial 322 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:36,728] Trial 323 finished with value: 0.877331759149941 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8890505854477223, 'colsample_bytree': 0.9126999961375758, 'reg_lambda': 0.0438747844844716, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:36,788] Trial 324 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:36,872] Trial 325 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:36,985] Trial 326 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:37,130] Trial 327 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:37,214] Trial 328 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:37,304] Trial 329 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:37,384] Trial 330 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:37,479] Trial 331 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:37,617] Trial 332 finished with value: 0.8770956316410862 and parameters: {'tree_method': 'hist', 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8861351716375689, 'colsample_bytree': 0.9998261984263023, 'reg_lambda': 0.03995542105036145, 'n_estimators': 10000, 'early_stopping_rounds': 50, 'scale_pos_weight': 0.2839506172839506}. Best is trial 118 with value: 0.880047225501771.\n",
            "[I 2025-03-30 02:42:37,694] Trial 333 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:38,011] Trial 334 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:38,082] Trial 335 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:38,258] Trial 336 pruned. Trial was pruned at iteration 0.\n",
            "[I 2025-03-30 02:42:38,410] Trial 337 pruned. Trial was pruned at iteration 1.\n",
            "[I 2025-03-30 02:42:38,636] Trial 338 pruned. Trial was pruned at iteration 0.\n"
          ]
        }
      ],
      "source": [
        "sampler = optuna.samplers.TPESampler(seed=1488)\n",
        "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
        "tic = time.time()\n",
        "while time.time() - tic < 100:\n",
        "    study.optimize(objective, n_trials=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N8cyUhy92VM",
        "outputId": "ce93049c-6c8e-4180-e7a5-f34874c160be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best score = 0.880047225501771\n",
            "boosting params ---------------------------\n",
            "best boosting round: 13\n",
            "best tree params --------------------------\n",
            "tree_method : hist\n",
            "max_depth : 10\n",
            "min_child_weight : 6\n",
            "subsample : 0.8832189875922608\n",
            "colsample_bytree : 0.9975624205287873\n",
            "reg_lambda : 0.023953657047454315\n",
            "n_estimators : 10000\n",
            "early_stopping_rounds : 50\n",
            "scale_pos_weight : 0.2839506172839506\n"
          ]
        }
      ],
      "source": [
        "print(f'best score = {study.best_trial.value}')\n",
        "print('boosting params ---------------------------')\n",
        "print(f'best boosting round: {study.best_trial.user_attrs[\"best_iteration\"]}')\n",
        "print('best tree params --------------------------')\n",
        "for k, v in study.best_trial.params.items():\n",
        "    print(k, ':', v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qllw76Xa96st",
        "outputId": "b3729f1f-dd31-4e04-9adf-4eecd5c927a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.74      0.65        35\n",
            "           1       0.92      0.84      0.88       121\n",
            "\n",
            "    accuracy                           0.82       156\n",
            "   macro avg       0.75      0.79      0.76       156\n",
            "weighted avg       0.84      0.82      0.83       156\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.880047225501771"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_trial = XGBClassifier(**base_params, **study.best_trial.params)\n",
        "\n",
        "best_trial.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = best_trial.predict(X_test)\n",
        "y_score = best_trial.predict_proba(X_test)[:,1]\n",
        "\n",
        "\n",
        "print(metrics.classification_report(y_true, y_pred))\n",
        "metrics.roc_auc_score(y_true, y_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save model to the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cKUcBGbZKfGS"
      },
      "outputs": [],
      "source": [
        "# config is a local config.py file strored in the root of this direcotry\n",
        "from config import MODELS_SAVE_PATH\n",
        "\n",
        "best_trial.save_model(MODELS_SAVE_PATH.joinpath('melanin_binding.json'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test load model from the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from config import MODELS_SAVE_PATH\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgbc = XGBClassifier()\n",
        "\n",
        "model_path = MODELS_SAVE_PATH.joinpath('melanin_binding.json')\n",
        "xgbc.load_model(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.74      0.65        35\n",
            "           1       0.92      0.84      0.88       121\n",
            "\n",
            "    accuracy                           0.82       156\n",
            "   macro avg       0.75      0.79      0.76       156\n",
            "weighted avg       0.84      0.82      0.83       156\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.880047225501771"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# assuming data is loaded!\n",
        "y_true = y_test\n",
        "y_pred = xgbc.predict(X_test)\n",
        "y_score = xgbc.predict_proba(X_test)[:,1]\n",
        "\n",
        "\n",
        "print(metrics.classification_report(y_true, y_pred))\n",
        "metrics.roc_auc_score(y_true, y_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hack",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
